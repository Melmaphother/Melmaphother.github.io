<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Denoising Diffusion Probabilistic Model 解读</title>
    <url>/2024/08/08/Denoising-Diffusion-Probabilistic-Model/</url>
    <content><![CDATA[<p>这篇文章是我关于 Denoising Diffusion Probabilistic Model
文章的解读。</p>
<span id="more"></span>
<h1 id="denoising-diffusion-model">Denoising Diffusion Model</h1>
<h2 id="数学基础">数学基础</h2>
<h3 id="jenson-不等式">Jenson 不等式</h3>
<h4 id="定义">定义</h4>
<p>设 <span class="math inline">\(X\)</span> 是一个随机变量，<span
class="math inline">\(f\)</span> 是一个定义在 <span
class="math inline">\(X\)</span> 的值域上的凸函数。那么，Jensen
不等式表示为：</p>
<p><span class="math display">\[ f(\mathbb{E}[X]) \leq \mathbb{E}[f(X)]
\]</span></p>
<p>其中，<span class="math inline">\(\mathbb{E}[X]\)</span> 是 <span
class="math inline">\(X\)</span> 的期望值，<span
class="math inline">\(\mathbb{E}[f(X)]\)</span> 是 <span
class="math inline">\(f(X)\)</span> 的期望值。</p>
<h4 id="取等条件">取等条件</h4>
<p>Jensen 不等式取等号的条件是：</p>
<ol type="1">
<li><span class="math inline">\(f\)</span> 是一个线性函数，即 <span
class="math inline">\(f(x) = ax + b\)</span> 形式的函数，其中 <span
class="math inline">\(a\)</span> 和 <span
class="math inline">\(b\)</span> 是常数。</li>
<li>或者，随机变量 <span class="math inline">\(X\)</span> 是退化的（即
<span class="math inline">\(X\)</span> 是常数），因此 <span
class="math inline">\(\mathbb{E}[X] = X\)</span>。</li>
</ol>
<h3 id="kl-散度-kl-divergence">KL 散度 KL Divergence</h3>
<h4 id="定义-1">定义</h4>
<p>对于两个概率分布 P 和 Q，KL 散度 <span
class="math inline">\(D_{KL}(P||Q)\)</span> 定义如下：</p>
<p><span class="math display">\[
D_{KL}(P || Q) = \sum_{x\in \chi}P(x)\log \frac{P(x)}{Q(x)}
\]</span></p>
<p>连续情况下：</p>
<p><span class="math display">\[
D_{KL}(P || Q) = \int_{-\infty}^{\infty}p(x)\log \frac{p(x)}{q(x)}
\]</span></p>
<p>KL 散度衡量的是当我们使用分布 Q 来近似分布 P
时所<strong>损失的信息量</strong>。它表示的是使用分布 Q 而不是分布 P
进行编码时，所增加的额外信息量。</p>
<h4 id="特性">特性</h4>
<ol type="1">
<li><p>非负性：KL 散度总是非负的，即 <span
class="math inline">\(D_{KL}(P||Q) \geq 0\)</span>。当且仅当 <span
class="math inline">\(P=Q\)</span> 时，KL 散度为 0。</p>
<p>证明：<span class="math inline">\(-log(x)\)</span> 为凸函数，根据
Jenson 不等式：</p>
<p><span class="math display">\[
\begin{aligned}
D_{KL} &amp;= \sum_{i=1}^{n} P(x_i)\cdot \log \frac{P(x_i)}{Q(x_i)}\\
&amp;= \sum_{i=1}^{n} P(x_i)\cdot (-\log \frac{Q(x_i)}{P(x_i)})\\
&amp;\geq -\log(\sum_{i=1}^{n}P(x_i)\cdot \frac{Q(x_i)}{P(x_i)}) \\
&amp;=-\log (\sum_{i=1}^{n}Q(x_i))\\
&amp;=0
\end{aligned}
\]</span></p></li>
<li><p>非对称性：KL 散度是非对称的，<span
class="math inline">\(D_{KL}(P||Q) \neq D_{KL}(Q||P)\)</span>。</p></li>
</ol>
<blockquote>
<p>（需要高斯积分技巧）高斯分布的 KL 散度：若 <span
class="math inline">\(p \sim N(\mu_1, \sigma_1^2)\)</span>，<span
class="math inline">\(q\sim N(\mu_2,\sigma_2^2)\)</span>​，则有：</p>
<p><span class="math display">\[
\begin{aligned}
D_{KL}(p\| q) &amp;=
\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}\sigma_1}e^{-\frac{(x-\mu_1)^2}{2\sigma_1^2}}\cdot
\log(\frac{e^{-\frac{(x-\mu_1)^2}{2\sigma_1^2}}/\sigma_1}{e^{-\frac{(x-\mu_2)^2}{2\sigma_2^2}}/\sigma_2})
\\
&amp;=\log \frac{\sigma_2}{\sigma_1} +
\frac{\sigma_1^2+(\mu_1-\mu_2)^2}{2\sigma_2^2}-\frac{1}{2}
\end{aligned}
\]</span></p>
<p>特别的，若 <span
class="math inline">\(\sigma_1=\sigma_2=\sigma\)</span>：</p>
<p><span class="math display">\[
D_{KL}(p\|q)=\frac{1}{2\sigma^2}\|\mu_1-\mu_2\|^2
\]</span></p>
</blockquote>
<ol start="3" type="1">
<li><p>KL 散度可以写为：</p>
<p><span class="math display">\[
D_{KL}(p|| q) = H(p, q) - H(p)
\]</span></p>
<p>也就是 <strong>交叉熵 - 原分布的熵</strong></p></li>
<li><p>KL 散度还可以写为： <span class="math display">\[
D_{KL}(p|| q) = \mathbb{E}_{x\sim p(x)}\left[\log
\frac{p(x)}{q(x)}\right]
\]</span> 也就是 <strong><span class="math inline">\(x\)</span> 服从分布
<span class="math inline">\(p(x)\)</span> 下，<span
class="math inline">\(\log \frac{p(x)}{q(x)}\)</span>
的期望。</strong></p></li>
</ol>
<h3 id="重参数化方法-reparameterization">重参数化方法
Reparameterization</h3>
<p>若想从目标分布 <span class="math inline">\(\mathcal{N}(\mu,
\sigma^2)\)</span> 进行采样，可以先从标准高斯分布中采样得到一个随机变量
<span
class="math inline">\(\epsilon\)</span>，将采样的随机变量进行线性变换：</p>
<p><span class="math display">\[
z = \mu + \sigma\cdot\epsilon, \quad \epsilon \sim \mathcal{N}(0,I)
\]</span></p>
<blockquote>
<p>重参数化特性：<strong>可微性</strong>，
这种重参数化方式使得采样过程保持可微性，因为 <span
class="math inline">\(\mu\)</span> 和 <span
class="math inline">\(\sigma\)</span> 只是通过简单的线性变换作用在 <span
class="math inline">\(\epsilon\)</span>
上。这意味着在反向传播时，梯度可以通过 <span
class="math inline">\(\mu\)</span> 和 <span
class="math inline">\(\sigma\)</span>​ 传递，从而可以优化这些参数。</p>
</blockquote>
<p>下文中有一个记号：</p>
<p><span class="math display">\[
\mathcal{N}(x;\mu,\sigma^2)
\]</span></p>
<p>表示 <span class="math inline">\(x\)</span> 是 <span
class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span>
分布的一个抽样，利用重参数方法，可以写作：</p>
<p><span class="math display">\[
x = \mu + \sigma\cdot\epsilon, \quad \epsilon \sim \mathcal{N}(0,I)
\]</span></p>
<h3 id="高斯分布的线性组合">高斯分布的线性组合</h3>
<p>设 x 和 y 是<strong>独立</strong>的高斯分布随机变量，并且 <span
class="math inline">\(x \sim \mathcal{N}(\mu_x, \sigma_x^2)\)</span>
，<span class="math inline">\(y \sim \mathcal{N}(\mu_y,
\sigma_y^2)\)</span>，则其线性组合：</p>
<p><span class="math display">\[
\alpha x + \beta y \sim \mathcal{N}(\alpha\mu_x + \beta\mu_y,
\alpha^2\sigma_x^2+\beta^2\sigma_y^2)
\]</span></p>
<p>特别的，若 x 和 y 是<strong>独立的标准高斯分布</strong>，也就是 <span
class="math inline">\(x\sim\mathcal{N}(0,I)\)</span>，<span
class="math inline">\(y\sim\mathcal{N}(0,I)\)</span>，则其线性组合：</p>
<p><span class="math display">\[
\alpha x + \beta y \sim \mathcal{N}(0, \alpha^2+\beta^2)
\]</span></p>
<h3 id="似然函数-lf-和最大似然估计-mle">似然函数 LF 和最大似然估计
MLE</h3>
<ol type="1">
<li><p>似然函数 <code>Likelihood Function</code></p>
<p>度量在给定参数的条件下，观测数据的可能性。</p>
<p>数学描述：给定参数 <span class="math inline">\(\theta\)</span>
和一组观测数据 <span class="math inline">\(x\)</span>，似然函数 <span
class="math inline">\(L(\theta)\)</span>
定义为观测数据在这些参数下出现的概率。表示为：</p>
<p><span class="math display">\[
L(\theta;x) = p(x|\theta)
\]</span></p>
<p>对数似然函数可以表示为：</p>
<p><span class="math display">\[
\ell(\theta;x)=\log L(\theta;x) = \log p(x|\theta)
\]</span></p></li>
</ol>
<blockquote>
<p>例如设一枚硬币抛出时正面朝上的概率为 <span
class="math inline">\(p\)</span>​，做三次独立抛掷实验，发现两次向上一次向下，如何建
模这个实验，就是似然函数可以干的事情。虽然似然函数可以用概率分布来计算，但是似然函数并不等同于概率分布（比如在概率分布后加一个常数也可以作为似然函数）[From
ChatGPT 4o]：</p>
<ul>
<li><p><strong>概率密度函数</strong>用于描述在给定参数下数据出现的概率。</p></li>
<li><p><strong>似然函数</strong>用于在给定观测数据下估计参数的可能性。</p></li>
</ul>
</blockquote>
<ol start="2" type="1">
<li><p>最大似然估计 <code>Maximum Likelihood Estimation</code></p>
<p>找一组参数 <span
class="math inline">\(\theta\)</span>，使得观测数据的似然函数最大化。一般先取
<span class="math inline">\(\log\)</span>​
求最大值。这里也可以看出：<strong>似然函数并不一定是概率</strong>，也并不一定是
0 到 1 之间。</p></li>
</ol>
<h3
id="expectation-maximization-算法和置信下界-elbo">Expectation-Maximization
算法和置信下界 ELBO</h3>
<blockquote>
<p>参考 <a
href="https://bookdown.org/hezhijian/book/est.html">数理统计讲义</a>，EM
算法用于求解<strong>不完备数据的最大似然估计</strong>，在这种情况中，直接对观测数据求最大似然估计比较困难。但是可以借用隐变量来获取似然函数的置信下界。</p>
<p>注：这里下标 <span
class="math inline">\(\mathbb{E}_{q(z|x,\theta)}\)</span> 均为 <span
class="math inline">\(\mathbb{E}_{z\sim q(z|x,\theta)}\)</span>
的省略。</p>
</blockquote>
<p>设完备数据为 <span class="math inline">\((x,z)\)</span>，其中 <span
class="math inline">\(x\)</span> 为观测数据，<span
class="math inline">\(z\)</span> 不可观测数据（潜在变量或隐变量
<code>latent variation</code>）</p>
<p>设观测数据 <span class="math inline">\(x\)</span> 的似然函数为 <span
class="math inline">\(L(\theta;x) =
p(x|\theta)\)</span>​，由联合分布的特性：</p>
<p><span class="math display">\[
\begin{aligned}
L(\theta ; x) &amp;= p(x|\theta)=\int p(x, z | \theta) dz \\
&amp;= \int \frac{q(z|x, \theta) p(x, z | \theta)}{q(z|x, \theta)} dz \\
&amp;= \mathbb{E}_{q(z|x, \theta)} \left[ \frac{p(x, z | \theta)}{q(z|x,
\theta)} \right]
\end{aligned}
\]</span></p>
<p>其中 $ p(y, z | ) $ 为完备数据的密度函数，$ q(z|x, ) $
为密度函数且满足：如果 $ q(z|x, ) = 0 $，则 $p(x, z | ) = 0
$。对数似然函数：</p>
<p><span class="math display">\[
\ell (\theta ; x) = \log \left( \mathbb{E}_{q(z|x, \theta)} \left[
\frac{p(x, z | \theta)}{q(z|x, \theta)} \right] \right) \geq
\mathbb{E}_{q(z|x, \theta)} \left[ \log \left( \frac{p(x, z |
\theta)}{q(z|x, \theta)} \right) \right])。
\]</span></p>
<p>其中应用了<span class="math inline">\(-log(x)\)</span> 为凸函数和
Jenson 不等式。根据 Jenson 不等式的取等条件，当且仅当 <span
class="math inline">\(p(x, z | \theta)/q(z|x, \theta)\)</span>​ 是一个与
<span class="math inline">\(z\)</span> 无关的常数，等号成立。</p>
<p>还有一种方式可以推导出这个结果，利用 <span class="math inline">\(\int
q(z|x,\theta) \text{d} z= 1\)</span>，可得：</p>
<p><span class="math display">\[
\begin{aligned}
\ell (\theta ; x) &amp;= \log p(x|\theta) \\
&amp;= \log p(x|\theta) \int q(z|x,\theta) \text{d}z \\
&amp;= \int q(z|x,\theta)\log p(x|\theta) \text{d}z \\
&amp;= \mathbb{E}_{q (z|x, \theta)} [\log p(x|\theta)] \\
&amp;= \mathbb{E}_{q (z|x, \theta)} \left[ \log \frac{p(x,
z|\theta)}{p(z|x,\theta)} \right] \\
&amp;= \mathbb{E}_{q (z|x, \theta)} \left[ \log \frac{p(x, z|\theta)q
(z|x, \theta)}{p(z|x,\theta)q (z|x, \theta)} \right] \\
&amp;= \mathbb{E}_{q (z|x, \theta)} \left[ \log \frac{p(x, z|\theta)}{q
(z|x, \theta)} \right] + \mathbb{E}_{q (z|x, \theta)} \left[ \log
\frac{q (z|x, \theta)}{p (z|x, \theta)} \right] \\
&amp;= \mathbb{E}_{q (z|x, \theta)} \left[ \log \frac{p(x, z|\theta)}{q
(z|x, \theta)} \right] + D_{KL}(q (z|x, \theta)||p (z|x, \theta)) \\
&amp;\geq \mathbb{E}_{q (z|x, \theta)} \left[ \log \frac{p(x,
z|\theta)}{q (z|x, \theta)} \right]
\end{aligned}
\]</span></p>
<p>当且仅当 <span class="math inline">\(q(z|x,\theta) =
p(z|x,\theta)\)</span> 时，取等号。事实上，这和上述的取等条件：当且仅当
<span class="math inline">\(p(x, z | \theta)/q(z|x, \theta)\)</span>
是一个与 <span class="math inline">\(z\)</span> 无关的常数是一致的。</p>
<blockquote>
<p>若 <span class="math inline">\(q(z|x,\theta) =
p(z|x,\theta)\)</span>，则：</p>
<p><span class="math display">\[
\frac{p(x, z | \theta)}{q(z|x, \theta)} = p(x|\theta)\cdot
\frac{p(z|x,\theta)}{q(z|x,\theta)} = p(x|\theta)
\]</span></p>
<p>是一个与 <span class="math inline">\(z\)</span>​ 无关的常数。</p>
<p>若 <span class="math inline">\(p(x, z | \theta)/q(z|x,
\theta)\)</span> 是一个与 <span class="math inline">\(z\)</span>
无关的常数：</p>
<p><span class="math display">\[
\frac{p(x, z | \theta)}{q(z|x, \theta)} = p(x|\theta)\cdot
\frac{p(z|x,\theta)}{q(z|x,\theta)}
\]</span></p>
<p>所以 <span
class="math inline">\(\frac{p(z|x,\theta)}{q(z|x,\theta)}\)</span>
必是一个与 <span class="math inline">\(z\)</span> 无关的常数，由于二者对
z 的积分均为 1，所以该常数只能为 1，也就是 <span
class="math inline">\(q(z|x,\theta) = p(z|x,\theta)\)</span></p>
</blockquote>
<p>也就是说：<strong>最大似然有一个置信下界（Evidence Lower
Bound）ELBO</strong></p>
<p>EM 算法后续的迭代过程忽略。</p>
<h3 id="联合分布和边缘分布">联合分布和边缘分布</h3>
<p>对于两个连续型随机变量 <span class="math inline">\(X\)</span> 和
<span class="math inline">\(Y\)</span> 的联合概率密度函数 <span
class="math inline">\(f_{X,Y}(x,y)\)</span>​，可以通过积分得到各自的边缘概率密度函数。</p>
<p><span class="math display">\[
f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dy
\]</span></p>
<p><span class="math display">\[
f_Y(y) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dx
\]</span></p>
<p>条件分布也可以通过联合分布和边缘分布得到：</p>
<p><span class="math display">\[
f_{Y \mid X}(y \mid x) = \frac{f_{X,Y}(x,y)}{f_X(x)}
\]</span></p>
<h3 id="fubini-定理">Fubini 定理</h3>
<p>假设 <span class="math inline">\(A\)</span> 和 <span
class="math inline">\(B\)</span> 是完备测度空间。假设 <span
class="math inline">\(f(x,y)\)</span> 是 <span class="math inline">\(A
\times B\)</span> 上的可测函数。</p>
<p>如果 <span class="math inline">\(f(x,y)\)</span> 在 <span
class="math inline">\(A\times B\)</span> 上绝对可积，即：</p>
<p><span class="math display">\[
\int_{A \times B} |f(x, y)| \, d(x, y) &lt; \infty,
\]</span></p>
<p>那么</p>
<p><span class="math display">\[
\int_A \left( \int_B f(x, y) \, dy \right) dx = \int_B \left( \int_A
f(x, y) \, dx \right) dy = \int_{A \times B} f(x, y) \, d(x, y)
\]</span></p>
<h2 id="生成模型-generative-model">生成模型 Generative Model</h2>
<p>Generative Model
本质是通过一个已知的概率模型来拟合所给的数据样本。</p>
<p>需要通过模型得到一个带参数的分布。即如果训练数据的分布函数为 <span
class="math inline">\(p_{data}(x)\)</span> ，生成样本的分布函数为 <span
class="math inline">\(p_{model}(x)\)</span>​
，希望<strong>得到的分布</strong>和<strong>训练数据的分布</strong>尽可能相似。</p>
<h3 id="variation-autoencoder-vae">Variation AutoEncoder VAE</h3>
<p>VAE 的架构设计了两个网络：Encoder，将观察的数据 x 映射到隐变量 z
上；Decoder，从采样的 z 中解码回 x。从实践的角度，VAE 需要训练两套参数
<span class="math inline">\(\theta\)</span> 和 <span
class="math inline">\(\phi\)</span>​</p>
<p>VAE 方法使用最大似然路线和上述的 ELBO。看起来很完美，但是问题在于
ELBO
只是一个下界，离真实分布很远的下界也是下界。必须把这个下界抬的足够高才能得到一个好的效果。由于需要用深度学习网络来建模近似分布
<span
class="math inline">\(q(z|\eta)\)</span>，而深度学习的优化算法是基于反向传播算法（Back
Propagation），如果要从分布 <span
class="math inline">\(q(z|\eta)\)</span>​
中采样，采样这个操作会<strong>打断梯度的传递</strong>。</p>
<p>所以说使用最大似然路线的 VAE 方法，效果并不如
GAN。要想避免这个问题，只能使用高斯分布加重参数化的技巧来避免无法求梯度的问题。事实上，VAE
算法在实现的时候增加了多个假设，有些牵强，反过来限制了它能力的上限。</p>
<p>业界针对 VAE 的问题做了很多尝试，DM
可以算作是其中一种比较成功的尝试。</p>
<h2 id="denoising-diffusion-probabilistic-model">Denoising Diffusion
Probabilistic Model</h2>
<p>VAE 想一步到位，同时训练 Encoder 和
Decoder，能够将原始图片映射到隐变量中，又能解码回来，看起来是非常困难的。一个常见的降低问题难度的思路是能不能只训练
Encoder 或 Decoder。而 Diffusion Model 就是去掉了 Encoder
部分的学习，只关心如何学好 Decoder，即逆向过程中如何重建数据。</p>
<p>DDPM 建模：</p>
<img src="/2024/08/08/Denoising-Diffusion-Probabilistic-Model/1.png" class="" title="DDPM">
<h3 id="前向过程">前向过程</h3>
<h4 id="简单介绍">简单介绍</h4>
<p>输入图像 <span class="math inline">\(x_0\)</span>，经过时间 <span
class="math inline">\(T\)</span>​ 个步骤，逐步向其添加高斯噪声。</p>
<blockquote>
<p>这里的前向过程并不等同于 MLP 中的前向过程 [From ChatGPT 4o]：</p>
<ul>
<li>Denoising Deffusion Model
的前向过程是一个<strong>逐步添加噪声</strong>的过程。目标是学习在<strong>添加噪声</strong>和<strong>去除噪声</strong>之间的映射，从而能够从噪声中恢复原始图像。</li>
<li>MLP
的前向过程是通过多层计算，将输入数据逐步<strong>变换成输出数据</strong>。目标是通过学习数据的特征，进行
Classfication 或 Regression 等下游任务。</li>
</ul>
</blockquote>
<p>当 <span class="math inline">\(T\)</span>​
足够大时，得到的加噪后的图像便接近一个<strong>高斯噪声图像</strong>。DDPM
Paper 中给出的典型值为 1000。</p>
<h4 id="数学描述">数学描述</h4>
<blockquote>
<p>设在前向的每一步通过向图像 <span
class="math inline">\(x_{t-1}\)</span> 中添加高斯噪声得到 <span
class="math inline">\(x_t\)</span> 的过程称为 <span
class="math inline">\(q(x_t|x_{t-1})\)</span>​</p>
<p><strong>前向过程没有任何参数，也没有任何训练过程！</strong></p>
</blockquote>
<p>给定初始分布 <span class="math inline">\(x_0 \sim
q(x)\)</span>，当前时刻 <span class="math inline">\(t\)</span>
下，添加的高斯噪声仅仅与当前时刻的一个固定值 <span
class="math inline">\(\beta_t\)</span> （<span
class="math inline">\(\beta\)</span> 一般是个很小的值，原文中取了 <span
class="math inline">\(\beta_1= 1\times 10^{-4}\)</span> 到 <span
class="math inline">\(\beta_T = 0.02\)</span>
的等差数列）和前一个时刻的状态 <span
class="math inline">\(x_{t-1}\)</span> 而定，加入的高斯噪声均值为 <span
class="math inline">\(\mu_t = \sqrt{1-\beta_t}x_{t-1}\)</span>，方差为
<span class="math inline">\(\Sigma_t = \beta_t
I\)</span>，故前向过程为：</p>
<p><span class="math display">\[
q(x_t|x_{t-1}) = \mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1}, \beta_t I)
\]</span></p>
<p>DDPM 的前向过程可以认为是一个 Markov 过程，从输入 <span
class="math inline">\(x_0\)</span> 到 <span
class="math inline">\(x_T\)</span> 的后验概率分布可以表示为：</p>
<p><span class="math display">\[
q(x_{1:T}|x_0) = \prod _{t=1}^{T}q(x_t|x_{t-1})
\]</span></p>
<blockquote>
<p>需要注意的是：这里 <span
class="math inline">\(q(x_t|x_{t-1})\)</span>
<strong>并不是两个状态之间的转移概率</strong>！！并且其本身<strong>不是一个条件概率，是一个条件概率分布</strong>！只是一般条件概率分布写作
<span
class="math inline">\(q_{X|Y}(x|y)\)</span>。<strong>条件概率分布同样也适用
Bayes 定理。</strong></p>
<p>这两个状态之间的转移概率应该为 1，因为按照原文的话：... called the
forward process or diffusion process: <strong>is fixed to</strong> a
Markov chain that gradually adds Gaussian noise to the data
...，也就是说 <span class="math inline">\(t-1\)</span> 状态一定会转移到
<span class="math inline">\(t\)</span> 状态。</p>
<p>另外<strong>这里 <span class="math inline">\(x_{1:T}\)</span> 表示
<span class="math inline">\(x_1,x_2,\cdots,x_T\)</span>
的联合分布</strong>，下文同理。</p>
</blockquote>
<p><strong>但是这样算太麻烦了，为了得到 <span
class="math inline">\(x_T\)</span>，就得重复采样 <span
class="math inline">\(T\)</span>
次再求积。</strong>但是可以使用重参数化方法来简化这个过程：</p>
<p>对任意的时间 <span class="math inline">\(t\)</span>，为了得到 <span
class="math inline">\(t\)</span> 时刻的采样：
每一个状态首先采集一个二维标准正态分布变量 <span
class="math inline">\(\epsilon_{1:T} \sim \mathcal{N}(0,
I)\)</span>，然后通过参数 <span class="math inline">\(\beta_t\)</span>
由 <span class="math inline">\(x_{t-1}\)</span> 获得 <span
class="math inline">\(x_t\)</span>：</p>
<p><span class="math display">\[
x_t = \sqrt{1 - \beta_t} x_{t-1} + \sqrt{\beta_t} \epsilon_{t-1}
\]</span></p>
<p>按照原论文的符号表示：<span class="math inline">\(\alpha_t =
1-\beta_t\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
x_t &amp;= \sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon_{t-1}\\
&amp;=\sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_{t-1}}\epsilon_{t-2})+\sqrt{1-\alpha_t}\epsilon_{t-1}\\
&amp;=\sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{\alpha_t} \cdot
\sqrt{1 - \alpha_{t-1}} \epsilon_{t-2} + \sqrt{1 - \alpha_t}
\epsilon_{t-1}
\end{aligned}
\]</span></p>
<p>由于 <span class="math inline">\(\epsilon_{t-1}\)</span> 和 <span
class="math inline">\(\epsilon_t\)</span>​ 均服从标准高斯分布 <span
class="math inline">\(\mathcal{N}(0,
I)\)</span>，<strong>由高斯分布的线性组合</strong>，有：</p>
<p><span class="math display">\[
\begin{aligned}
\left(\sqrt{\alpha_t} \cdot \sqrt{1 -
\alpha_{t-1}}\right)^2+\left(\sqrt{1 - \alpha_t} \right)^2 = 1-\alpha_t
\alpha_{t-1}
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
x_t &amp;=\sqrt{\alpha_t \alpha_{t-1}} x_{t-2}  + \sqrt{1 - \alpha_t
\alpha_{t-1}} \bar{\epsilon}_{t-2}
\end{aligned}
\]</span></p>
<p>逐渐推导到 <span class="math inline">\(x_0\)</span>，并设 <span
class="math inline">\(\overline{\alpha_{t}} =
\alpha_t\alpha_{t-1}\cdots\alpha_1\)</span> 可得：</p>
<p><span class="math display">\[
x_t = \sqrt{\bar{\alpha_t}}x_0 + \sqrt{1-\bar{\alpha_t}}\epsilon
\]</span></p>
<p>也可以写为：</p>
<p><span class="math display">\[
x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}} \left( x_t - \sqrt{1 -
\bar{\alpha}_t} \epsilon \right)
\]</span></p>
<p>综上，在已知初始样本分布：<span class="math inline">\(x_0 \sim
q(x)\)</span> 的情况下，为什么在时间步 <span
class="math inline">\(t\)</span> 产生一个样本，可以根据表达式：</p>
<p><span class="math display">\[
x_t \sim q(x_t|x_0) = \mathcal{N}\left( x_t; \sqrt{\bar{\alpha}_t} x_0,
(1 - \bar{\alpha}_t) \mathbf{I} \right)
\]</span></p>
<p>其中 <span class="math inline">\(\beta_t\)</span>
是一个超参数，可以<strong>预先计算所有 <span
class="math inline">\(\alpha_t\)</span> 和 <span
class="math inline">\(\overline{\alpha_t}\)</span> 以加速。</strong></p>
<h3 id="反向过程">反向过程</h3>
<h4 id="简单介绍-1">简单介绍</h4>
<p>从噪声图像 <span class="math inline">\(x_T\)</span>
开始，通过一个神经网络学习 <span class="math inline">\(x_{t-1}\)</span>
到 <span class="math inline">\(x_t\)</span>
添加的噪声，然后通过逐渐去噪的方式得到最后要生成的图像。</p>
<blockquote>
<p>注意：</p>
<ul>
<li>前向过程中的 <span class="math inline">\(x_T\)</span>
是由初始的干净图像 <span class="math inline">\(x_0\)</span> 加 <span
class="math inline">\(T\)</span> 步高斯噪声得来，当 <span
class="math inline">\(T\)</span> 足够大时，收敛到各向同性的高斯噪声</li>
<li>反向过程中的 <span class="math inline">\(x_T\)</span>
直接取随机噪声</li>
</ul>
</blockquote>
<h4 id="数学描述-1">数学描述</h4>
<blockquote>
<p>注：这里为了和原文保持一致，由于前向过程没有参数，而反向过程有参数
<span class="math inline">\(\theta\)</span>，所以将反向过程 <span
class="math inline">\(p(x|\theta)\)</span> 写作 <span
class="math inline">\(p_\theta(x)\)</span>，前向过程写作 <span
class="math inline">\(q(x)\)</span>。与数学基础的符号表示（<span
class="math inline">\(p(\theta|x)\)</span>）有出入。</p>
</blockquote>
<p>首先，当时间步长 <span class="math inline">\(T \to \infty\)</span>
时，隐变量 <span class="math inline">\(x_T\)</span>
可以认为是一个各向同性的高斯分布，反之，DDPM 的反向过程 <span
class="math inline">\(p(x_{t-1}|x_t)\)</span>
则是一个去噪过程。即先随机采样一个二位高斯噪声，然后逐步去噪，最终得到一个和真实图像分布一致的生成图像
<span class="math inline">\(x_0\)</span>。</p>
<p>然而反向过程 <span class="math inline">\(p(x_{t-1}|x_t)\)</span>
是未知的，DDPM 指出，可以使用一个神经网络来学习这个去噪过程：在时刻
<span class="math inline">\(t\)</span> 的分布 <span
class="math inline">\(x_t\)</span> 是已知的，神经网络的目的是根据 <span
class="math inline">\(x_t\)</span> 来学习（近似） <span
class="math inline">\(x_{t-1}\)</span> 的概率分布函数 <span
class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span>。为了简化模型的训练难度，DDPM
假设反向去噪过程<strong>滤除的也是高斯噪声</strong>，并且只对均值和方差进行参数化。DDPM
的反向过程可以建模为：</p>
<p><span class="math display">\[
p_\theta(x_{t-1}|x_t) =
\mathcal{N}(x_{t-1};\mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t))
\]</span></p>
<p>其中 <span class="math inline">\(\theta\)</span>​ 是模型的参数。</p>
<p>同时，DDPM 的前向过程中我们假设每一个时间扩散均为 Markov
过程，那么其反向过程也可以认为是 Markov
过程，所以反向过程可以表示为：</p>
<p><span class="math display">\[
p_\theta (x_{0:T}) = p(x_T) \cdot \prod_{t=1}^{T} p_\theta (x_{t-1}|x_t)
\]</span></p>
<p>其中，<span class="math inline">\(p(x_T) =
\mathcal{N}(x_T;0,I)\)</span> 是随机采样的高斯噪声（所以这里不需要写参数
<span class="math inline">\(\theta\)</span>），<span
class="math inline">\(p_\theta (\mathbf{x}_{t-1}|\mathbf{x}_t)\)</span>
是一个均值和方差需要计算的高斯分布。</p>
<h3 id="denoising-diffusion-model-的训练和采样">Denoising Diffusion
Model 的训练和采样</h3>
<h4 id="损失函数推导">损失函数推导</h4>
<p>由 Diffusion 的反向过程，可以自然的想到，真实数据分布是 <span
class="math inline">\(x_0\sim
q(x_0)\)</span>，反向过程建模的最终结果概率分布可以写作 <span
class="math inline">\(p_\theta(x_0)\)</span>，为了衡量二者分布的相似性，在深度学习中，显然的，可以使用交叉熵作为其损失函数，并使用优化算法得到最优参数：</p>
<p><span class="math display">\[
L_{ideal}=H(p_\theta(x_0),q(x_0))=\mathbb{E}_{q(x_0)}(-\log
p_\theta(x_0))
\]</span></p>
<p>由于我们无法直接知道反向过程的建模，也就是无法直接得出 <span
class="math inline">\(p_\theta(x_0)\)</span>，但是在整个过程中，我们有隐变量
<span
class="math inline">\(x_{1:T}\)</span>，可以辅助我们获得似然函数的置信下界（ELBO），结合数学基础（注意这里由于负号的加入，不等式方向有所改变），推导如下：</p>
<p><span class="math display">\[
\begin{aligned}
-\log p_\theta(x_0) &amp;\leq -\mathbb{E}_{q(x_{1:T}|x_0)}\left[\log
\frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)}\right]\\
&amp;=\mathbb{E}_{q(x_{1:T}|x_0)}\left[\log
\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}\right] \\
\end{aligned}
\]</span></p>
<p>对该不等式左右取期望，设右边为 <span
class="math inline">\(L\)</span>，利用 Fubini 定理：</p>
<p><span class="math display">\[
\begin{aligned}
L_{ideal}
&amp;\leq\mathbb{E}_{q(x_0)}\left(\mathbb{E}_{q(x_{1:T}|x_0)}\left[\log
\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}\right]\right) \\
&amp;=\mathbb{E}_{q(x_{0:T})}\left[\log
\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}\right] \\
&amp;:= L
\end{aligned}
\]</span></p>
<p>之后就是<strong>一段冗长</strong>的代入表达式，运用 Beyas
公式简化这个损失函数的过程：</p>
<blockquote>
<p>推导过程会用到一个 Bayes 公式：</p>
<p><span class="math display">\[
\begin{aligned}
q(x_{t-1} | x_t, x_0) &amp;= \frac{q(x_{t-1}, x_t, x_0)}{q(x_t, x_0)}\\
&amp;= q(x_t | x_{t-1}, x_0) \cdot \frac{q(x_{t-1}, x_0)}{q(x_t, x_0)}
\\
&amp;=q(x_t | x_{t-1}, x_0) \cdot \frac{q(x_{t-1} | x_0)}{q(x_t |
x_0)}\\
&amp;=q(x_t | x_{t-1}) \cdot \frac{q(x_{t-1} | x_0)}{q(x_t | x_0)} \quad
\end{aligned}
\]</span></p>
<p>所以：</p>
<p><span class="math display">\[
q(x_t | x_{t-1})=q(x_{t-1} | x_t, x_0)\cdot\frac{q(x_t | x_0)}{q(x_{t-1}
| x_0)}
\]</span></p>
</blockquote>
<p><span class="math display">\[
\begin{aligned}
L &amp;= \mathbb{E}_{q(x_{0:T})} \left[ \log
\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} \right] \\
&amp;= \mathbb{E}_{q(x_{0:T})} \left[ \log \frac{\prod_{t=1}^T
q(x_t|x_{t-1})}{p(x_T) \prod_{t=1}^T p_\theta(x_{t-1}|x_t)} \right]
\quad 代入 \\
&amp;= \mathbb{E}_{q(x_{0:T})} \left[ -\log p(x_T) + \sum_{t=1}^T \log
\frac{q(x_t|x_{t-1})}{p_\theta(x_{t-1}|x_t)} \right] \quad \log 的性质
\\
&amp;= \mathbb{E}_{q(x_{0:T})} \left[ -\log p(x_T) + \sum_{t=2}^T \log
\frac{q(x_t|x_{t-1})}{p_\theta(x_{t-1}|x_t)} + \log
\frac{q(x_1|x_0)}{p_\theta(x_0|x_1)} \right]\\
&amp;= \mathbb{E}_{q(x_{0:T})} \left[ -\log p(x_T) + \sum_{t=2}^T \log
\left( \frac{q(x_{t-1}|x_t, x_0)}{p_\theta(x_{t-1}|x_t)}\cdot
\frac{q(x_t|x_0) }{q(x_{t-1}|x_0) }\right) + \log
\frac{q(x_1|x_0)}{p_\theta(x_0|x_1)} \right] \\
&amp;= \mathbb{E}_{q(x_{0:T})} \left[ -\log p(x_T) + \sum_{t=2}^T \log
\frac{q(x_{t-1}|x_t, x_0)}{p_\theta(x_{t-1}|x_t)} + \sum_{t=2}^T \log
\frac{q(x_t|x_0) }{q(x_{t-1}|x_0) } + \log
\frac{q(x_1|x_0)}{p_\theta(x_0|x_1)} \right] \\
&amp;= \mathbb{E}_{q(x_{0:T})} \left[  -\log p(x_T) + \sum_{t=2}^T \log
\frac{q(x_{t-1}|x_t, x_0)}{p_\theta(x_{t-1}|x_t)} + \log\frac{q(x_T|x_0)
}{q(x_1|x_0) } + \log \frac{q(x_1|x_0)}{p_\theta(x_0|x_1)} \right] \\
&amp;= \mathbb{E}_{q(x_{0:T})} \left[ \log \frac{ q(x_T|x_0)}{p(x_T)} +
\sum_{t=2}^T \log \frac{q(x_{t-1}|x_t, x_0)}{p_\theta(x_{t-1}|x_t)} -
\log p_\theta(x_0|x_1) \right] \\
\end{aligned}
\]</span></p>
<p>运用熵、KL 散度、联合分布与边缘分布的关系：</p>
<ol type="1">
<li>第一项：</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}_{q(x_{0:T})} \left[ \log\frac{ q(x_T|x_0)}{p(x_T)}\right]
&amp;=\int\text{d}x_{0:T}~ q(x_{0:T})\cdot \log\frac{
q(x_T|x_0)}{p(x_T)} \\
&amp;=\int\log\frac{ q(x_T|x_0)}{p(x_T)}\text{d}x_0\text{d}x_T \int
q(x_{0:T}) \text{d}_{x_{1:T-1}}\\
&amp;=\int q(x_T)\cdot \log\frac{
q(x_T|x_0)}{p(x_T)}\text{d}x_0\text{d}x_T\\
&amp;=\int q(x_0)\text{d}x_0\int q(x_T|x_0)\cdot \log\frac{
q(x_T|x_0)}{p(x_T)}\text{d}x_T\\
&amp;=\mathbb{E}_{q(x_0)}\left[ D_{KL}(q(x_T|x_0)\|p(x_T))\right]
\end{aligned}
\]</span></p>
<ol start="2" type="1">
<li>第二项同理：</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}_{q(x_{0:T})} \sum_{t=2}^T \log \frac{q(x_{t-1}|x_t,
x_0)}{p_\theta(x_{t-1}|x_t)} &amp;= \int\text{d}x_{0:T}~
q(x_{0:T})\cdot\sum_{t=2}^T \log \frac{q(x_{t-1}|x_t,
x_0)}{p_\theta(x_{t-1}|x_t)} \\
&amp;=\sum_{t=2}^T \int\log \frac{q(x_{t-1}|x_t,
x_0)}{p_\theta(x_{t-1}|x_t)}\text{d} x_0\text{d} x_{t-1}\text{d}x_t\int
q(x_{0:T})\text{d}x_{0:T/(0,t-1,t)}\\
&amp;=\sum_{t=2}^T\int q(x_0,x_{t-1},x_t) \log \frac{q(x_{t-1}|x_t,
x_0)}{p_\theta(x_{t-1}|x_t)}\text{d} x_0\text{d} x_{t-1}\text{d}x_t\\
&amp;=\sum_{t=2}^T\int q(x_0,x_t)\text{d} x_0\text{d}x_t\int
q(x_{t-1}|x_0,x_t) \log \frac{q(x_{t-1}|x_t,
x_0)}{p_\theta(x_{t-1}|x_t)}\text{d} x_{t-1}\\
&amp;=\sum_{t=2}^T\mathbb{E}_{q(x_0,x_t)}\left[D_{KL}(q(x_{t-1}|x_t,
x_0)\|p_\theta(x_{t-1}|x_t))\right]
\end{aligned}
\]</span></p>
<ol start="3" type="1">
<li>第三项也同理：</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
-\mathbb{E}_{q(x_{0:T})} \left[\log p_\theta(x_1|x_0)\right] &amp;= -
\int\text{d}x_{0:T}~ q(x_{0:T})\cdot \left[\log p_\theta(x_1|x_0)\right]
\\
&amp;=-\int \log p_\theta(x_1|x_0)\text{d}x_0 \text{d}x_1 \int
q(x_{0:T})\text{d}x_{0:T/(0,1)} \\
&amp;=-\int q(x_0,x_1) \log p_\theta(x_1|x_0)\text{d}x_0 \text{d}x_1\\
&amp;=-\mathbb{E}_{q(x_0,x_1)} \left[\log p_\theta(x_1|x_0)\right]
\end{aligned}
\]</span></p>
<p>所以最终的 Loss 可以写成：</p>
<p><span class="math display">\[
\begin{aligned}
L &amp;= \mathbb{E}_{q(x_0)}\left[ D_{KL}(q(x_T|x_0)\|p(x_T))\right] \\
&amp;+ \sum_{t=2}^T \mathbb{E}_{q(x_0,x_t)} \left[ D_{KL}(q(x_{t-1}|x_t,
x_0) \| p_\theta(x_{t-1}|x_t)) \right] -\mathbb{E}_{q(x_0,x_1)}
\left[\log p_\theta(x_1|x_0)\right]
\end{aligned}
\]</span></p>
<p>也可以写为：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;L = L_T+L_{T-1}+\cdots+L_0 \\
&amp;L_T = \mathbb{E}_{q(x_0)}\left[ D_{KL}(q(x_T|x_0)\|p(x_T))\right]
\\
&amp;L_{t-1} = \mathbb{E}_{q(x_0,x_t)} \left[ D_{KL}(q(x_{t-1}|x_t, x_0)
\| p_\theta(x_{t-1}|x_t)) \right]; \quad 1 \leq t-1 \leq T - 1 \\
&amp;L_0 = -\mathbb{E}_{q(x_0,x_1)} \left[\log p_\theta(x_1|x_0)\right]
\end{aligned}
\]</span></p>
<p>这里：</p>
<ul>
<li><span class="math inline">\(L_T\)</span>
可以看作<strong>最后的噪声输入</strong>和标准的<strong>高斯先验</strong>的接近程度，因为这一部分没有可以训练的参数，我们可以将它视作常数。</li>
<li><span class="math inline">\(L_{t-1}\)</span> 可以看作真实后验分布
<span class="math inline">\(q(x_{t-1}|x_t,x_0)\)</span> 与预测分布 <span
class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span>​ 的接近程度，DDPM
的目标也正是保证<strong>真实的去噪过程</strong>和<strong>模型预测的去噪过程</strong>尽可能一致。</li>
<li><span class="math inline">\(L_0\)</span>
可以看作图像重建（reconstruction）损失。</li>
</ul>
<h4 id="l_t-1-项讨论"><span class="math inline">\(L_{t-1}\)</span>
项讨论</h4>
<ol type="1">
<li><p><span class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span></p>
<p>反向过程中已经介绍了，DDPM 假设反向去噪也是去除高斯噪声，所以：</p>
<p><span class="math display">\[
p_\theta(x_{t-1}|x_t) =
\mathcal{N}(x_{t-1};\mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t))
\]</span></p></li>
<li><p><span class="math inline">\(q(x_{t-1}|x_t, x_0)\)</span>​</p>
<p>为了求该分布，需要再次使用上述的 Bayes 定理：</p>
<blockquote>
<p><span class="math display">\[
\begin{aligned}
q(x_{t-1} | x_t, x_0) &amp;= \frac{q(x_{t-1}, x_t, x_0)}{q(x_t, x_0)}\\
&amp;= q(x_t | x_{t-1}, x_0) \cdot \frac{q(x_{t-1}, x_0)}{q(x_t, x_0)}
\\
&amp;=q(x_t | x_{t-1}, x_0) \cdot \frac{q(x_{t-1} | x_0)}{q(x_t |
x_0)}\\
&amp;=q(x_t | x_{t-1}) \cdot \frac{q(x_{t-1} | x_0)}{q(x_t | x_0)} \quad
\end{aligned}
\]</span></p>
</blockquote>
<p>由前向过程可知：</p>
<p><span class="math display">\[
\begin{aligned}
q(x_t|x_{t-1}) &amp;= \mathcal{N}(x_t;\sqrt{\alpha_t}x_{t-1},
(1-\alpha_t) I)\\
q(x_{t-1}|x_0) &amp;=\mathcal{N}\left( x_{t-1};
\sqrt{\bar{\alpha}_{t-1}} x_0, (1 - \bar{\alpha}_{t-1}) \mathbf{I}
\right) \\
q(x_{t}|x_0) &amp;=\mathcal{N}\left( x_{t}; \sqrt{\bar{\alpha}_t} x_0,
(1 - \bar{\alpha}_t) \mathbf{I} \right)
\end{aligned}
\]</span></p>
<p>这样代入公式，高斯分布展开再合成，一通计算，具体计算可以查看论文 <a
href="https://arxiv.org/pdf/2208.11970">Understanding Diffusion Models:
A Unified Perspective</a> 公式 [71] 到公式
[84]。总之，它的计算结果表明：</p>
<p><span class="math display">\[
q(x_{t-1} | x_t, x_0) =
\mathcal{N}(x_{t-1},\tilde{\mu}_t(x_t,x_0),\tilde{\beta}_t I)
\]</span></p>
<p>其中：</p>
<p><span class="math display">\[
\tilde{\mu}_t (x_t, x_0) = \frac{\sqrt{\alpha_t} (1 -
\overline{\alpha_{t-1}}) x_t + \sqrt{\overline{\alpha_{t-1}}}
(1-\alpha_t) x_0}{1 - \overline{\alpha_t}}
\]</span></p>
<p><span class="math display">\[
\tilde{\beta}_t=\frac{(1 - \alpha_t)(1 - \overline{\alpha_{t-1}})}{1 -
\overline{\alpha_t}}=\frac{1 - \overline{\alpha_{t-1}}}{1 -
\overline{\alpha_t}}\beta_t
\]</span></p>
<p>发现<strong>均值是与变量相关的，而方差无关</strong>，所以可以假设所预测的分布也可以表示为：</p>
<p><span class="math display">\[
p_\theta(x_{t-1}|x_t) =
\mathcal{N}(x_{t-1};\mu_{\theta}(x_t,t),\sigma_t^2\mathbf{I})
\]</span></p>
<p>其中 <span
class="math inline">\(\sigma_t^2=\tilde{\beta}_t\)</span>，那么根据数学基础中两个方差相同高斯分布的
KL 散度，可以得到：</p>
<p><span class="math display">\[
L_{t-1}=\mathbb{E}_{q(x_0,x_t)}\left[\frac{1}{2\sigma_t^2}\|\tilde{\mu}_t
(x_t, x_0)-\mu_{\theta}(x_t,t)\|\right]
\]</span></p></li>
<li><p><span class="math inline">\(L_{t-1}\)</span></p>
<blockquote>
<p>第一项</p>
</blockquote>
<p>可以看到，第一项包含了 <span class="math inline">\(x_t\)</span> 和
<span class="math inline">\(x_0\)</span>，而第二项包含 <span
class="math inline">\(x_t\)</span> 和 <span
class="math inline">\(t\)</span>​，并不对称，但是我们有：</p>
<p><span class="math display">\[
x_t(x_0,\epsilon) = \sqrt{\overline{\alpha_t}}x_0 +
\sqrt{1-\overline{\alpha_t}}\epsilon\\
x_0 = \frac{1}{\sqrt{\overline{\alpha}_t}} \left( x_t - \sqrt{1 -
\overline{\alpha}_t} \epsilon_0 \right)
\]</span></p>
<p>代入 <span class="math inline">\(\tilde{\mu}_t (x_t, x_0)\)</span>
的表达式，一通计算可得：</p>
<p><span class="math display">\[
\tilde{\mu}_t (x_t, x_0) = \frac{1}{\sqrt{\alpha_t}} \left(x_t - \frac{1
- \alpha_t}{\sqrt{1 - \overline{\alpha_t}}}\epsilon\right)
\]</span></p>
<p>所以 <span class="math inline">\(L_{t-1}\)</span> 可以写为：</p>
<p><span class="math display">\[
L_{t-1}=\mathbb{E}_{q(x_0,x_t)}\left[\frac{1}{2\sigma_t^2}\left\|\frac{1}{\sqrt{\alpha_t}}
\left(x_t - \frac{1 - \alpha_t}{\sqrt{1 -
\overline{\alpha_t}}}\epsilon\right)
-\mu_{\theta}(x_t,t)\right\|^2\right]
\]</span></p>
<blockquote>
<p>第二项是按照第一项的格式进行假设的</p>
</blockquote>
<p>（来自 DDMP）上述公式说明 <span
class="math inline">\(\mu_\theta\)</span> 在给定 <span
class="math inline">\(x_t\)</span> 时必须预测 <span
class="math inline">\(\frac{1}{\sqrt{\alpha_t}} \left(x_t - \frac{1 -
\alpha_t}{\sqrt{1 - \overline{\alpha_t}}}\epsilon\right)\)</span>，而
<span class="math inline">\(x_t\)</span>​
可以作为模型输入，为了方便计算，可以尽量消去相同的项以及合并同类项。对于
<span class="math inline">\(\mu_\theta\)</span>，它只取决于我们如何
<strong>参数化</strong> 它，为了方便，我们可以选择如下参数化：</p>
<p><span class="math display">\[
\mu_\theta (x_t, t) = \frac{1}{\sqrt{\alpha_t}} \left(x_t - \frac{1 -
\alpha_t}{\sqrt{1 - \overline{\alpha_t}}}\epsilon_\theta(x_t,t)\right)
\]</span></p>
<p>联立上述公式，<span class="math inline">\(L_{t-1}\)</span>
就可以被写为：</p>
<p><span class="math display">\[
L_{t-1}=\mathbb{E}_{q(x_0,x_t)}\left[\frac{(1-\alpha_t)^2}{2\sigma_t^2\alpha_t(1-\overline{\alpha_t})}\left\|\epsilon-\epsilon_\theta(x_t,t)\right\|^2\right]
\]</span></p>
<p>由于训练时 <span class="math inline">\(x_0\)</span> 和每轮的 <span
class="math inline">\(\epsilon\)</span>
才是输入，所以训练时损失（下标和值）不能出现 <span
class="math inline">\(x_t\)</span>，<span
class="math inline">\(L_{t-1}\)</span> 要改写为：</p>
<p><span class="math display">\[
L_{t-1}=\mathbb{E}_{q(x_0,\epsilon)}\left[\frac{(1-\alpha_t)^2}{2\sigma_t^2\alpha_t(1-\overline{\alpha_t})}\left\|\epsilon-\epsilon_\theta(\sqrt{\overline{\alpha_t}}x_0
+ \sqrt{1-\overline{\alpha_t}}\epsilon,t)\right\|^2\right]
\]</span></p>
<blockquote>
<p>至此，我们将之前预测 <span class="math inline">\(\tilde
\mu_t\)</span> 的过程变为了预测 <span
class="math inline">\(\epsilon\)</span> 的过程，在 DDPM
论文中提到：实际上无论预测谁都可以，预测 <span
class="math inline">\(\epsilon\)</span>
只是一种参数化的形式（事实上甚至还可以预测 <span
class="math inline">\(x_0\)</span>，只不过经过 DDPM
的验证，这种方式在实验的早期就会导致样本质量变差）。通过预测 <span
class="math inline">\(\epsilon\)</span> 和 <span
class="math inline">\(x_0\)</span> 的消融试验中，验证了预测 <span
class="math inline">\(\epsilon\)</span> 的有效性。</p>
</blockquote>
<p>而采样时，<span class="math inline">\(x_t\)</span> 和采样 <span
class="math inline">\(z\)</span> 是输入，所以采样时不能出现 <span
class="math inline">\(x_0\)</span>，采样的过程为：</p>
<p><span class="math display">\[
p_\theta(x_{t-1}|x_t) =
\mathcal{N}(x_{t-1};\mu_{\theta}(x_t,t),\sigma_t^2\mathbf{I})
\]</span></p>
<p><span class="math display">\[
x_{t-1}=\frac{1}{\sqrt{\alpha_t}} \left(x_t - \frac{1 -
\alpha_t}{\sqrt{1 -
\overline{\alpha_t}}}\epsilon_\theta(x_t,t)\right)+\sigma_tz\quad
z\sim\mathcal{N}(0,I)~\text{if~t&gt;1,else z=0}
\]</span></p></li>
</ol>
<h4 id="l_0-项讨论"><span class="math inline">\(L_0\)</span> 项讨论</h4>
<blockquote>
<p>DDPM 原论文指出从 <span class="math inline">\(x_0\)</span> 到 <span
class="math inline">\(x_1\)</span> 应该是一个离散化过程，因为图像 RGB
值都是离散化的。DDPM 针对 <span
class="math inline">\(p_\theta(x_1|x_0)\)</span>
构建了一个离散化的分段积分累乘，有点类似基于分类目标的自回归（auto-regressive）学习。</p>
</blockquote>
<p>（DDPM Explanation）类比在普通 VAE 中的
ELMO，这一项可以使用蒙特卡洛估计来近似和优化。</p>
<p>可以看到，<strong>在采样的最后一步，使用了无噪声的采样</strong>，也就是：
<span class="math display">\[
x_0=\frac{1}{\sqrt{\alpha_1}} \left(x_1 - \frac{1 - \alpha_1}{\sqrt{1 -
\overline{\alpha_1}}}\epsilon_\theta(x_1,1)\right)
\]</span></p>
<h4 id="训练和采样">训练和采样</h4>
<p>由上述的讨论，我们已经得到了训练的优化目标（即损失函数），以及采样时的反向建模，所以，训练和采样的流程也是非常显然了：</p>
<ol type="1">
<li><p>训练（Training）</p>
<img src="/2024/08/08/Denoising-Diffusion-Probabilistic-Model/2.png" class="" title="Training"></li>
<li><p>采样（Sampling）</p>
<img src="/2024/08/08/Denoising-Diffusion-Probabilistic-Model/3.png" class="" title="Sampling"></li>
</ol>
]]></content>
      <categories>
        <category>Diffusion</category>
      </categories>
      <tags>
        <tag>Diffusion</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2024/07/29/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very
first post. Check <a href="https://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a
href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a
href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>我的个人简历</title>
    <url>/2024/08/03/My-Curriculum-Vitae/</url>
    <content><![CDATA[<p>这篇文章主要介绍了我本科生活中的一些经历和项目。</p>
<span id="more"></span>
<h2 id="教育背景">教育背景</h2>
<ul>
<li><strong>中国科学技术大学</strong>
<ul>
<li>专业：计算机科学与技术</li>
<li>学历：本科</li>
<li>研究方向：时间序列、深度学习、大模型</li>
</ul></li>
</ul>
<h2 id="科研">科研？</h2>
<ul>
<li><strong>时间序列预测模型 预测算法研究</strong>
<ul>
<li>项目介绍：基于 TimeMAE 自监督学习架构的时序预测任务。TimeMAE
是一种新颖的自监督范式，用于学习基于 Transformer
网络的可转移的时间序列表征。</li>
<li>工作内容：研究 TimeMAE
的自监督学习架构，设计时序预测任务的实验方案，进行代码实现和实验，并与当前时序预测工作进行对比。</li>
<li>项目地址：<a
href="https://github.com/Melmaphother/TimeMAE-Forecasting">TimeMAE-Forecasting</a></li>
<li>时间：2024年1月 - 2024年4月</li>
</ul></li>
</ul>
<h2 id="比赛">比赛</h2>
<ul>
<li><strong>Meta KDD Cup 2024 CRAG: Comprehensive RAG Benchmark
团队队员</strong>
<ul>
<li>比赛介绍：Meta KDD Cup 2024 的一个子任务，旨在提供一个全面的 RAG
基准测试集，以评估各种 RAG 模型的性能。</li>
<li>工作内容：负责知识图谱的分析与解析，微调 llama 3 以及 prompt
修正，模型的融合与后处理。</li>
<li>成绩：Phase 1 第六名 Phase 2 银牌</li>
<li>时间：2024年4月 - 2024年5月</li>
</ul></li>
<li><strong>2024 年第十五届全国大学生数学竞赛</strong>
<ul>
<li>荣誉：全国一等奖</li>
<li>时间：2023年11月 - 2023年12月</li>
</ul></li>
</ul>
<h2 id="项目">项目</h2>
<ul>
<li><strong>基于 MySQL 的银行管理系统全栈开发 项目负责人</strong>
<ul>
<li>项目介绍：基于 MySQL、Django、HTML
开发一个简易的银行管理系统，包括前端界面、后端数据库维护和中间件。</li>
<li>项目成果：实现了用户注册、登录、存取款、转账等功能，并实现了银行管理系统的数据可视化。</li>
<li>项目地址：<a
href="https://github.com/Melmaphother/2024-USTC-Database-Lab2">银行管理系统</a></li>
<li>时间：2024年5月 - 2024年6月</li>
</ul></li>
<li><strong>基于爬虫、检索、推荐技术的简易搜索引擎 团队队长</strong>
<ul>
<li>项目介绍：基于爬虫（Crawler）、检索（Retrieval）、推荐（Recommendation）、知识图谱（KG）等技术，实现一个简易搜索引擎。</li>
<li>工作职责：负责爬虫、检索、知识图谱技术的实现，项目文档撰写和项目答辩。</li>
<li>项目地址：<a
href="https://github.com/Melmaphother/USTC-2023-WebInfo-Labs/tree/main">简易搜索引擎</a></li>
<li>时间：2023年10月 - 2024年1月</li>
</ul></li>
<li><strong>基于 FPGA 的五级流水线 CPU 设计 项目负责人</strong>
<ul>
<li>项目介绍：基于 risc-v 指令集和 FPGA 开发板的五级流水线 CPU
设计，包括指令译码、数据通路、控制通路、缓存、输入输出模块等。</li>
<li>项目成果：实现了基于 risc-v 指令集的五级流水线 CPU
设计，并分析不同缓存配置下 CPU 的频率和性能。</li>
<li>项目地址：<a
href="https://github.com/Melmaphother/ustc-codh-2023/tree/main/LABH6">五级流水线
CPU</a></li>
<li>时间：2023年5月 - 2023年6月</li>
</ul></li>
<li><strong>基于 zero-copy 技术，对 ROS2 机器人操作系统的实时性优化
团队成员</strong>
<ul>
<li>项目介绍：基于 zero-copy 技术，对 ROS2
机器人操作系统进行实时性优化，实现数据传输的超低延迟，解决多个物理中断的实时沟通问题。</li>
<li>工作职责：负责 ROS2
机器人操作系统的实时性优化，项目文档撰写和项目答辩。</li>
<li>项目地址：<a
href="https://github.com/OSH-2023/Code-ForWWWard/tree/main">ROS2
实时性优化</a></li>
<li>时间：2023年3月 - 2023年7月</li>
</ul></li>
</ul>
<h2 id="专业">专业</h2>
<ul>
<li><strong>程序语言</strong>：C/C++、Python、SQL</li>
<li><strong>开发技术</strong>：熟悉 Linux、Git，了解 Docker、Django
等框架与中间件</li>
<li><strong>知识领域</strong>：Pytorch
深度学习框架、时间序列预测、知识图谱、机器学习</li>
</ul>
<h2 id="联系方式">联系方式</h2>
<ul>
<li><strong>个人邮箱</strong>：melmaphother@gmail.com</li>
<li><strong>学校邮箱</strong>：wdy030428@mail.ustc.edu.cn</li>
<li><strong>Github</strong>：<a
href="https://github.com/Melmaphother">Melmaphother</a></li>
</ul>
]]></content>
      <categories>
        <category>CV</category>
      </categories>
      <tags>
        <tag>CV</tag>
      </tags>
  </entry>
</search>
